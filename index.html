<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dominated Novelty Search: Breaking Out of the Grid</title>
    <link rel="stylesheet" href="css/style.css">
    <!-- MathJax for LaTeX rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</head>
<body>
    <!-- Main Content -->
    <div class="main-wrapper">
        <!-- Header teaser banner -->
        <div class="header-banner">
            <img src="images/dns_header_banner.png" alt="DNS t-SNE embedding with sample portraits">
        </div>

        <header>
            <h1 class="title">The MAP-Elites Grid is Dead.<br>Long Live Dominated Novelty Search!</h1>

            <div class="author-list">
                <a href="https://ryanboldi.github.io" class="author-link highlighted">Ryan Bahlous-Boldi*<sup>1</sup></a>
                <span class="separator">·</span>
                <a href="https://maxencefaldor.github.io" class="author-link highlighted">Maxence Faldor*<sup>2</sup></a>
            </div>
            <div class="author-list secondary">
                <a href="https://lucagrillotti.github.io" class="author-link">Luca Grillotti<sup>2</sup></a>
                <span class="separator">·</span>
                <a href="#" class="author-link">Hannah Janmohamed<sup>2</sup></a>
                <span class="separator">·</span>
                <a href="#" class="author-link">Lisa Coiffard<sup>2</sup></a>
                <span class="separator">·</span>
                <a href="https://lspector.github.io" class="author-link">Lee Spector<sup>3</sup></a>
                <span class="separator">·</span>
                <a href="https://www.antoinecully.com" class="author-link">Antoine Cully<sup>2</sup></a>
            </div>
            <div class="affiliations">
                <span class="affiliation-item"><sup>1</sup>MIT CSAIL</span>
                <span class="affiliation-item"><sup>2</sup>Imperial College London</span>
                <span class="affiliation-item"><sup>3</sup>Amherst College</span>
            </div>

            <div class="paper-links">
                <a href="https://arxiv.org/abs/2502.00593" class="paper-btn" target="_blank">
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>
                    Paper
                </a>
                <a href="https://github.com/adaptive-intelligent-robotics/QDax" class="paper-btn" target="_blank">
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                    QDax
                </a>
                <a href="https://github.com/icaros-usc/pyribs" class="paper-btn" target="_blank">
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                    PyRibs
                </a>
            </div>

            <div class="paper-authors">
                GECCO 2025
            </div>
        </header>

        <style>
            .header-banner {
                max-width: 1600px;
                margin: 0 auto 20px;
                padding-top: 40px;
                text-align: center;
            }
            .header-banner img {
                max-width: 100%;
                height: auto;
                border-radius: 4px;
                box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            }
        </style>

        <main>
            <!-- Abstract / Hook -->
            <div class="hook" id="hook">
                Quality-Diversity algorithms have long promised open-ended evolution, but MAP-Elites, the most prominent QD algorithm, has been trapped in a rigid grid that requires predefined bounds and can't scale beyond a handful of dimensions.
                <strong>Dominated Novelty Search</strong> breaks free. It works in unbounded descriptor spaces, scales to hundreds of dimensions, and adapts to learned embeddings that change during evolution. These are prerequisites for truly open-ended systems, and DNS achieves all three while outperforming MAP-Elites on standard benchmarks.
            </div>

            <!-- Tom Cruise Teaser - moved up for immediate impact -->
            <section id="teaser" style="margin-top: 40px; max-width: 880px; margin-left: auto; margin-right: auto; padding: 0 20px;">
                <h2>The Proof: 5,000 Diverse Portraits of Tom Cruise</h2>
                <p>
                    When you ask Stable Diffusion to generate "a portrait of Tom Cruise," you get the same image
                    over and over. Quality-Diversity algorithms have the ability to change that by searching for
                    diverse, high-quality solutions simultaneously. However, most QD algorithms rely on grids that
                    can't handle high-dimensional spaces like the 512-dimensional CLIP embeddings we need here.
                    DNS can. Here, we use it to <strong>illuminate the output space of a diffusion model</strong>.
                </p>
                <p>
                    The setup is simple. We evolve the initial noise that Stable Diffusion begins its denoising process from.
                    For each generated image, we compute its CLIP embedding. The <strong>fitness</strong> is the CLIP similarity
                    between the image and the text "Tom Cruise" (higher means it looks more like him). The <strong>behavior descriptor</strong>
                    is the 512-dimensional CLIP embedding itself, capturing visual attributes like pose, lighting, and style.
                </p>
                <p>
                    DNS selects for images that are both high-quality AND diverse. You survive if you're different
                    from images that score higher than you. The result? 5,000 distinct, high-quality portraits, each one
                    looking like Tom Cruise but with different poses, lighting, expressions, and styles.
                </p>
            </section>
        </main>

        <!-- Interactive CLIP space visualization - Wide figure -->
        <div class="wide-figure" id="clip-viz-figure">
            <div class="figure-title" style="font-size: 24pt; margin-bottom: 20px;">Dominated Novelty Search for Images of Tom Cruise</div>
                    <div class="clip-viz-container">
                        <div class="clip-viz-main">
                            <canvas id="clip-canvas"></canvas>
                            <div class="clip-hover-preview" id="clip-hover-preview">
                                <img id="clip-hover-img" src="" alt="">
                                <div class="clip-hover-info">
                                    <span class="clip-hover-fitness" id="clip-hover-fitness"></span>
                                </div>
                            </div>
                        </div>
                        <div class="clip-viz-legend">
                            <div class="clip-legend-title">CLIP Score (Fitness)</div>
                            <div class="clip-color-bar"></div>
                            <div class="clip-legend-labels">
                                <span>Low</span>
                                <span>High</span>
                            </div>
                            <div class="clip-stats">
                                <p><strong>5,000</strong> evolved portraits</p>
                                <p><strong>512-dim</strong> CLIP embeddings</p>
                                <p>Projected via <strong>t-SNE</strong></p>
                            </div>
                            <p class="clip-instruction">Hover over points to see portraits</p>
                        </div>
                    </div>
            <div class="figure-caption">
                DNS spreads solutions across the reachable regions while maintaining high CLIP scores.
                No grid was needed; the algorithm naturally discovered the structure of the space.
                <em>Points colored by CLIP score (yellow = higher).</em>
            </div>

            <style>
                    .clip-viz-container {
                        display: flex;
                        gap: 20px;
                        padding: 20px;
                        background: var(--bg-paper);
                        justify-content: center;
                        align-items: flex-start;
                    }
                    .clip-viz-main {
                        position: relative;
                        width: 900px;
                        height: 900px;
                        border: 1px solid var(--border-color);
                        background: var(--bg-subtle);
                    }
                    #clip-canvas {
                        width: 100%;
                        height: 100%;
                        cursor: crosshair;
                    }
                    .clip-hover-preview {
                        position: absolute;
                        display: none;
                        pointer-events: none;
                        z-index: 100;
                        background: var(--bg-paper);
                        border: 2px solid var(--border-color);
                        border-radius: 4px;
                        box-shadow: 0 4px 12px rgba(0,0,0,0.15);
                        overflow: hidden;
                    }
                    .clip-hover-preview.visible {
                        display: block;
                    }
                    #clip-hover-img {
                        width: 150px;
                        height: 150px;
                        object-fit: cover;
                        display: block;
                    }
                    .clip-hover-info {
                        padding: 6px 8px;
                        font-size: 9pt;
                        text-align: center;
                        background: var(--bg-subtle);
                        border-top: 1px solid var(--border-light);
                    }
                    .clip-hover-fitness {
                        font-family: var(--font-mono);
                        color: var(--text-secondary);
                    }
                    .clip-viz-legend {
                        width: 140px;
                        padding: 15px;
                        background: var(--bg-subtle);
                        border: 1px solid var(--border-light);
                        border-radius: 4px;
                    }
                    .clip-legend-title {
                        font-size: 9pt;
                        font-weight: 700;
                        margin-bottom: 8px;
                        color: var(--text-primary);
                    }
                    .clip-color-bar {
                        height: 12px;
                        border-radius: 2px;
                        background: linear-gradient(to right, #440154, #482878, #3e4a89, #31688e, #26828e, #1f9e89, #35b779, #6ece58, #b5de2b, #fde725);
                        margin-bottom: 4px;
                    }
                    .clip-legend-labels {
                        display: flex;
                        justify-content: space-between;
                        font-size: 8pt;
                        color: var(--text-secondary);
                        margin-bottom: 15px;
                    }
                    .clip-stats {
                        font-size: 9pt;
                        color: var(--text-secondary);
                        line-height: 1.6;
                    }
                    .clip-stats p {
                        margin: 4px 0;
                        text-align: left;
                    }
                    .clip-stats strong {
                        color: var(--text-primary);
                    }
                    .clip-instruction {
                        font-size: 8pt;
                        color: var(--text-secondary);
                        font-style: italic;
                        margin-top: 15px;
                        text-align: center;
                    }
                    @media (max-width: 1100px) {
                        .clip-viz-container {
                            flex-direction: column;
                            align-items: center;
                        }
                        .clip-viz-main {
                            width: 100%;
                            max-width: 700px;
                            height: 700px;
                        }
                        .clip-viz-legend {
                            width: 100%;
                            max-width: 700px;
                        }
                    }
                </style>

                <script>
                (function() {
                    let clipData = null;
                    let clipCanvas, clipCtx;
                    let clipHoveredIdx = -1;
                    const POINT_SIZE = 3;
                    const PADDING = 20;

                    // Viridis color scale
                    function viridisColor(t) {
                        t = Math.max(0, Math.min(1, t));
                        const colors = [
                            [68, 1, 84], [72, 40, 120], [62, 74, 137], [49, 104, 142],
                            [38, 130, 142], [31, 158, 137], [53, 183, 121], [110, 206, 88],
                            [181, 222, 43], [253, 231, 37]
                        ];
                        const idx = t * (colors.length - 1);
                        const i = Math.floor(idx);
                        const f = idx - i;
                        if (i >= colors.length - 1) return `rgb(${colors[colors.length-1].join(',')})`;
                        const c1 = colors[i], c2 = colors[i + 1];
                        return `rgb(${Math.round(c1[0] + f * (c2[0] - c1[0]))},${Math.round(c1[1] + f * (c2[1] - c1[1]))},${Math.round(c1[2] + f * (c2[2] - c1[2]))})`;
                    }

                    function drawClipViz() {
                        if (!clipData || !clipCanvas) return;
                        const container = document.querySelector('.clip-viz-main');
                        const width = container.offsetWidth;
                        const height = container.offsetHeight;

                        clipCtx.fillStyle = '#fafafa';
                        clipCtx.fillRect(0, 0, width, height);

                        const minFit = Math.min(...clipData.fitness);
                        const maxFit = Math.max(...clipData.fitness);

                        // Draw points
                        for (let i = 0; i < clipData.n; i++) {
                            const [nx, ny] = clipData.coords[i];
                            const x = PADDING + nx * (width - 2 * PADDING);
                            const y = PADDING + ny * (height - 2 * PADDING);
                            const fitNorm = (clipData.fitness[i] - minFit) / (maxFit - minFit);

                            clipCtx.beginPath();
                            clipCtx.arc(x, y, i === clipHoveredIdx ? POINT_SIZE + 2 : POINT_SIZE, 0, Math.PI * 2);
                            clipCtx.fillStyle = viridisColor(fitNorm);
                            clipCtx.fill();

                            if (i === clipHoveredIdx) {
                                clipCtx.strokeStyle = '#000';
                                clipCtx.lineWidth = 2;
                                clipCtx.stroke();
                            }
                        }
                    }

                    function getClipPointAt(mx, my) {
                        if (!clipData) return -1;
                        const container = document.querySelector('.clip-viz-main');
                        const width = container.offsetWidth;
                        const height = container.offsetHeight;
                        let closest = -1, minDist = 15;

                        for (let i = 0; i < clipData.n; i++) {
                            const [nx, ny] = clipData.coords[i];
                            const x = PADDING + nx * (width - 2 * PADDING);
                            const y = PADDING + ny * (height - 2 * PADDING);
                            const dist = Math.sqrt((mx - x) ** 2 + (my - y) ** 2);
                            if (dist < minDist) {
                                minDist = dist;
                                closest = i;
                            }
                        }
                        return closest;
                    }

                    function showClipPreview(idx, clientX, clientY) {
                        const preview = document.getElementById('clip-hover-preview');
                        const img = document.getElementById('clip-hover-img');
                        const fitness = document.getElementById('clip-hover-fitness');

                        if (idx < 0) {
                            preview.classList.remove('visible');
                            return;
                        }

                        img.src = `dns_clip_web_viewer/images/${idx}.jpg`;
                        fitness.textContent = `CLIP Score: ${clipData.fitness[idx].toFixed(3)}`;
                        preview.classList.add('visible');

                        // Position preview near cursor but within bounds
                        const container = document.querySelector('.clip-viz-main');
                        const rect = container.getBoundingClientRect();
                        let left = clientX - rect.left + 15;
                        let top = clientY - rect.top - 75;

                        // Keep within container bounds
                        if (left + 160 > container.offsetWidth) left = clientX - rect.left - 170;
                        if (top < 0) top = clientY - rect.top + 15;
                        if (top + 180 > container.offsetHeight) top = container.offsetHeight - 185;

                        preview.style.left = left + 'px';
                        preview.style.top = top + 'px';
                    }

                    function initClipViz() {
                        clipCanvas = document.getElementById('clip-canvas');
                        if (!clipCanvas) return;

                        clipCtx = clipCanvas.getContext('2d');

                        // Set canvas resolution
                        const container = document.querySelector('.clip-viz-main');
                        const dpr = window.devicePixelRatio || 1;
                        clipCanvas.width = container.offsetWidth * dpr;
                        clipCanvas.height = container.offsetHeight * dpr;
                        clipCtx.scale(dpr, dpr);

                        // Load data
                        fetch('dns_clip_web_viewer/metadata.json')
                            .then(r => r.json())
                            .then(data => {
                                clipData = data;
                                drawClipViz();
                            })
                            .catch(err => console.error('Failed to load CLIP data:', err));

                        // Mouse events for hover preview
                        clipCanvas.addEventListener('mousemove', (e) => {
                            const rect = clipCanvas.getBoundingClientRect();
                            const mx = e.clientX - rect.left;
                            const my = e.clientY - rect.top;

                            const idx = getClipPointAt(mx, my);
                            if (idx !== clipHoveredIdx) {
                                clipHoveredIdx = idx;
                                drawClipViz();
                            }
                            showClipPreview(idx, e.clientX, e.clientY);
                        });

                        clipCanvas.addEventListener('mouseleave', () => {
                            clipHoveredIdx = -1;
                            drawClipViz();
                            showClipPreview(-1, 0, 0);
                        });

                        // Redraw on resize
                        window.addEventListener('resize', () => {
                            const dpr = window.devicePixelRatio || 1;
                            clipCanvas.width = container.offsetWidth * dpr;
                            clipCanvas.height = container.offsetHeight * dpr;
                            clipCtx.scale(dpr, dpr);
                            drawClipViz();
                        });
                    }

                    // Initialize when DOM is ready
                    if (document.readyState === 'loading') {
                        document.addEventListener('DOMContentLoaded', initClipViz);
                    } else {
                        initClipViz();
                    }
                })();
                </script>
        </div>

        <main>
            <section style="max-width: 880px; margin-left: auto; margin-right: auto; padding: 0 40px;">
                <p>
                    This couldn't be done with traditional QD methods. CLIP embeddings have 512 dimensions: even with just 2 bins per dimension, you'd need $2^{512}$ grid cells, more than atoms in the observable universe. DNS doesn't need a grid; it works directly in continuous high-dimensional space.
                </p>
                <p>
                    <strong>How does it work?</strong> Keep reading to learn how DNS breaks free from the grid.
                </p>
            </section>
        </main>

        <!-- Figure 1 - Full width outside main -->
        <div class="wide-figure" id="figure1">
            <div class="figure-title">Figure 1: Breaking Out of the Grid</div>
            <div style="text-align: center; padding: 20px;">
                <img src="images/DNS_diagram_v4.pdf" alt="DNS Diagram" style="max-width: 100%; height: auto;" onerror="this.style.display='none'; this.nextElementSibling.style.display='block';">
                <p style="color: #666; font-style: italic; display: none;">
                    The MAP-Elites grid is limited when the descriptor space: (a) has complex topology,
                    (b) is discontinuous, (c) is unbounded, or (d) is high-dimensional.
                </p>
            </div>
            <div class="figure-caption">
                <strong>Figure 1.</strong> The MAP-Elites grid struggles when the achievable descriptor space
                has complex topological shapes, is discontinuous, unbounded, or high-dimensional.
                Dominated Novelty Search adapts dynamically to the natural structure of the solution space.
            </div>
        </div>

        <main>
            <article>
                <!-- Introduction -->
                <section id="intro">
                    <p>
                        Quality-Diversity (QD) is a family of evolutionary algorithms that generate diverse, high-performing
                        solutions through local competition. The key idea is that solutions should only compete with similar
                        solutions, not the entire population. This insight, inspired by natural evolution, is what distinguishes
                        QD from traditional evolutionary algorithms.
                    </p>
                    <p>
                        What makes solutions "similar"? That's defined by a <em>descriptor space</em>, a set of features that
                        characterize <em>how</em> a solution behaves, separate from how <em>well</em> it performs. For a walking
                        robot, descriptors might be foot contact patterns or gait style. For generated images, descriptors might
                        be visual features like pose, lighting, or style. QD algorithms maintain diversity across this descriptor
                        space while optimizing performance.
                    </p>
                    <p>
                        While research has focused on improving specific aspects of QD algorithms,
                        surprisingly little attention has been paid to the core mechanism itself. Most approaches implement
                        local competition through explicit collection mechanisms (fixed grids in MAP-Elites, or unstructured
                        archives in Novelty Search) that impose artificial constraints requiring predefined bounds or
                        hard-to-tune parameters.
                    </p>
                    <p>
                        <strong>Dominated Novelty Search</strong> takes a different approach. We show that QD methods can be
                        reformulated as Genetic Algorithms where local competition occurs through <em>fitness transformations</em>
                        rather than explicit collection mechanisms. DNS implements a novel competition strategy that dynamically
                        adapts to the shape and structure of the descriptor space, eliminating the need for predefined bounds,
                        grid structures, or fixed distance thresholds.
                    </p>
                    <p>
                        The result? A drop-in replacement for the grid mechanism in MAP-Elites that:
                    </p>
                    <ul>
                        <li>Significantly outperforms existing approaches across standard QD benchmarks</li>
                        <li>Works in high-dimensional descriptor spaces where grids are impossible</li>
                        <li>Requires no discretization, bounds, or threshold tuning</li>
                        <li>Adapts to a potentially changing descriptor space as evolution unfolds</li>
                        <li>Is available in <a href="https://github.com/adaptive-intelligent-robotics/QDax">QDax</a> and <a href="https://github.com/icaros-usc/pyribs">PyRibs</a>, or can be implemented from scratch in ~10 lines of code</li>
                    </ul>
                </section>

                <!-- Section 2: The Problem with Grids -->
                <section id="problem">
                    <h2>2. The Problem with Grids</h2>
                    <p>
                        MAP-Elites, the most popular QD algorithm, works by dividing the descriptor space into a grid.
                        Each cell holds exactly one solution, the best one found for that region. This is elegant and
                        simple, but it comes with fundamental limitations.
                    </p>
                    <p>
                        <strong>Grids don't scale.</strong> A 10×10 grid in 2D has 100 cells. Add a third dimension and you have 1,000 cells. With 10 dimensions, you need 10 billion cells. With the 512-dimensional CLIP embeddings we use in our experiments? You'd need $10^{512}$ cells, more than the number of atoms in the observable universe.
                    </p>
                    <p>
                        <strong>Grids need bounds.</strong> Traditional QD algorithms require you to specify bounds in advance, like "poses range from -90° to +90°" or "lighting ranges from dark to bright." But what if you don't know the bounds? What if you're working with learned embeddings like CLIP where dimensions have no human-interpretable meaning?
                    </p>
                    <p>
                        <strong>Grids lose information.</strong> Forcing continuous descriptor spaces into discrete cells throws away information. Two solutions at opposite corners of the same cell are treated as "the same location," even though they might be quite different. This limits the granularity of diversity that can be achieved.
                    </p>
                </section>

                <!-- Section 3: The Algorithm -->
                <section id="algorithm">
                    <h2>3. The Algorithm</h2>
                    <p>
                        QD algorithms are really just genetic algorithms with special fitness functions.
                        The "local competition" that makes QD work can be implemented by transforming fitness values before selection.
                        This means a simple fitness augmentation to a standard GA can give you a population-based QD algorithm
                        that outperforms MAP-Elites without any grids or archives. That's exactly what DNS does.
                    </p>
                    <p>
                        Dominated Novelty Search implements local competition through a simple but powerful idea.
                        A solution's survival depends on how different it is from solutions that are better than it.
                        If there's a better solution nearby in descriptor space, you're in trouble. But if you're doing something
                        different from everyone who's better than you, you get to stick around.
                    </p>
                    <p>
                        Solutions are ranked based on their distance to individuals that are better than them, and the worst are discarded.
                        The key insight is that we can transform fitness values based on local competition, rather than
                        using explicit collection mechanisms.
                    </p>

                    <h3>3.1. The Competition Function</h3>
                    <p>
                        For each solution $i$ in the population, we compute a "dominated novelty" score in three steps:
                    </p>

                    <div class="algorithm-box" id="algorithm-1">
                        <div class="algorithm-title">Algorithm 1: Dominated Novelty Search Competition</div>
                        <div class="algorithm-input">
                            <strong>Input:</strong> Population $\mathbf{X}$ with fitness values $\mathbf{f}$ and descriptors $\mathbf{d}$, locality parameter $k$
                        </div>
                        <div class="algorithm-output">
                            <strong>Output:</strong> Competition fitness $\tilde{f}_i$ for each solution $i$
                        </div>
                        <ol>
                            <li>
                                <span class="keyword">For</span> each solution $i$ in population:
                                <ol type="a">
                                    <li><strong>Identify dominating solutions:</strong> Find all solutions with superior fitness:
                                        $$\mathcal{D}_i = \{j \in \{1, \ldots, N\} \mid f_j > f_i\}$$
                                    </li>
                                    <li><strong>Compute descriptor distances:</strong> Calculate pairwise distances in descriptor space:
                                        $$d_{ij} = \|\mathbf{d}_i - \mathbf{d}_j\| \quad \forall j \in \mathcal{D}_i$$
                                    </li>
                                    <li><strong>Calculate dominated novelty score:</strong>
                                        $$\tilde{f}_i = \begin{cases}
                                            \frac{1}{k} \sum_{j \in \mathcal{K}_i} d_{ij} & \text{if } |\mathcal{D}_i| > 0 \\
                                            +\infty & \text{otherwise}
                                        \end{cases}$$
                                        where $\mathcal{K}_i$ contains indices of $k$ solutions in $\mathcal{D}_i$ with smallest distances.
                                    </li>
                                </ol>
                            </li>
                            <li><span class="keyword">Return</span> competition fitness $\tilde{\mathbf{f}}$</li>
                        </ol>
                    </div>

                    <p>
                        The intuition is elegant: <strong>a solution survives if it's either the best at what it does,
                        OR if it's doing something different from solutions that are better than it.</strong>
                    </p>
                    <ul>
                        <li><strong>Path 1: Be the best.</strong> If no one has higher fitness than you ($|\mathcal{D}_i| = 0$),
                            you automatically survive with infinite competition fitness.</li>
                        <li><strong>Path 2: Be different.</strong> If better solutions exist, you survive by being far away
                            from them in descriptor space. The farther you are from your $k$ nearest fitter neighbors,
                            the higher your competition fitness.</li>
                    </ul>

                    Another easy way to think about this is by thinking about the conditions under which a solution is eliminated.
                    In general, to be eleminated, there must be a solution that has a higher fitness score than you, and is also close-by.
                    As such, individuals that don't contribute to the population through performance nor diversity are eliminated.

                    <h3>3.2. The Full Algorithm</h3>
                    <p>
                        The complete DNS algorithm follows the standard QD framework, with the competition function
                        replacing traditional grid or archive mechanisms:
                    </p>

                    <div class="algorithm-box" id="algorithm-2">
                        <div class="algorithm-title">Algorithm 2: Dominated Novelty Search</div>
                        <div class="algorithm-input">
                            <strong>Input:</strong> Population size $N$, batch size $B$, locality parameter $k$
                        </div>
                        <div class="algorithm-output">
                            <strong>Output:</strong> Final population $\mathbf{X}$
                        </div>
                        <ol>
                            <li><strong>Initialize:</strong> Population $\mathbf{X}$ with fitness $\mathbf{f}$ and descriptors $\mathbf{d}$</li>
                            <li><span class="keyword">While</span> not converged <span class="keyword">do</span>:
                                <ol type="a">
                                    <li><strong>Reproduce:</strong> Generate $B$ offspring using genetic operators</li>
                                    <li><strong>Concatenate:</strong> Add offspring to existing population</li>
                                    <li><strong>Evaluate:</strong> Compute fitness and descriptors for all solutions</li>
                                    <li><strong>Compete:</strong> Transform fitness via competition function (Algorithm 1)</li>
                                    <li><strong>Select:</strong> Retain top-$N$ individuals by competition fitness $\tilde{f}$</li>
                                </ol>
                            </li>
                            <li><span class="keyword">Return</span> population $\mathbf{X}$</li>
                        </ol>
                    </div>

                    <p>
                        The parameter $k$ controls the locality of competition. Small $k$ (like 3) means very local
                        competition: you only need to be different from your immediate neighborhood. Large $k$ means
                        broader competition: you need to be different from many better solutions.
                    </p>
                </section>

                <!-- Section 4: Code Comparison -->
                <section id="code">
                    <h2>4. Just 10 Lines of Code</h2>
                    <p>
                        Like MAP-Elites, DNS is remarkably simple to implement. Here's a side-by-side comparison showing
                        that DNS is just as elegant as the algorithms it replaces:
                    </p>

                    <!-- Code comparison figure -->
                    <div class="opening-figure">
                        <div class="figure-title">Code Comparison: MAP-Elites vs DNS</div>
                        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 50px; padding: 20px 60px; max-width: 1000px; margin: 0 auto;">
                            <div style="background: #1e1e1e; color: #d4d4d4; padding: 16px; border-radius: 4px; font-family: monospace; font-size: 10pt;">
                                <div style="color: #569cd6; margin-bottom: 8px;"># MAP-Elites</div>
                                <pre style="margin: 0; white-space: pre-wrap;">
def map_elites(pop, grid):
    for gen in range(N_GENS):
        # Select and mutate
        children = mutate(select(pop))
        # Evaluate
        fit, desc = evaluate(children)
        # Add to grid
        for i, (f, d) in enumerate(zip(fit, desc)):
            cell = discretize(d, grid)
            if f > grid[cell].fitness:
                grid[cell] = children[i]
    return grid</pre>
                            </div>
                            <div style="background: #1e1e1e; color: #d4d4d4; padding: 16px; border-radius: 4px; font-family: monospace; font-size: 10pt;">
                                <div style="color: #569cd6; margin-bottom: 8px;"># Dominated Novelty Search</div>
                                <pre style="margin: 0; white-space: pre-wrap;">
def dns(pop, k=3):
    for gen in range(N_GENS):
        # Select and mutate
        children = mutate(select(pop))
        # Evaluate
        fit, desc = evaluate(children)
        # Merge and compete
        pop = concat(pop, children)
        scores = dominated_novelty(pop, k)
        # Keep top N
        pop = top_n(pop, scores, N)
    return pop</pre>
                            </div>
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 2.</strong> MAP-Elites requires discretizing the descriptor space into a grid.
                            DNS replaces this with a continuous competition function: no grid, no bounds, no discretization.
                        </div>
                    </div>

                    <p>
                        The key difference is that MAP-Elites uses <code>discretize()</code> and a grid structure, while DNS uses
                        <code>dominated_novelty()</code>, a function that computes competition scores based on distances
                        to fitter neighbors. Everything else is the same standard evolutionary loop.
                    </p>
                    <p>
                        DNS is available in two popular QD libraries:
                        <strong><a href="https://github.com/adaptive-intelligent-robotics/QDax">QDax</a></strong> (JAX-based, GPU-accelerated) and
                        <strong><a href="https://github.com/icaros-usc/pyribs">PyRibs</a></strong> (Python, NumPy-based).
                        Switching from MAP-Elites to DNS is typically a one-line change: replace the archive/grid
                        mechanism with DNS competition, and you're ready to go.
                    </p>
                </section>

                <!-- Section 5: Benchmark Results -->
                <section id="benchmarks">
                    <h2>5. Benchmark Results</h2>
                    <p>
                        We evaluated DNS against MAP-Elites, Threshold-Elites, and Cluster-Elites on standard
                        continuous control benchmarks including Walker (bipedal locomotion), Ant (quadrupedal movement),
                        and Ant Blocks (navigation with obstacles). Each experiment was repeated 10 times with
                        different seeds, using Mann-Whitney U tests with Holm-Bonferroni correction for statistical significance.
                    </p>

                    <div class="opening-figure">
                        <div class="figure-title">Figure 3: Benchmark Performance</div>
                        <div style="text-align: center; padding: 20px;">
                            <img src="images/all_environments_metrics_plot_4.png" alt="Benchmark Results" style="max-width: 100%; height: auto;">
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 3.</strong> QD-Score and Coverage over generations across MuJoCo environments.
                            DNS significantly outperforms Threshold-Elites and Cluster-Elites across all environments ($p < 10^{-9}$),
                            and outperforms MAP-Elites in Walker and Ant Blocks ($p < 10^{-3}$) where implicit constraints
                            limit the reachable descriptor space.
                        </div>
                    </div>

                    <p>
                        <strong>In Walker</strong>, DNS significantly outperforms MAP-Elites because certain foot-contact
                        proportions (like both feet never touching ground) are infeasible, leaving grid cells empty.
                        <strong>In Ant Blocks</strong>, obstacles create discontinuous descriptor spaces where some regions
                        are unreachable, wasting MAP-Elites grid cells.
                        <strong>In Ant</strong>, DNS and MAP-Elites perform competitively when the descriptor space
                        (final x,y position) aligns well with a 2D grid.
                    </p>
                </section>

                <!-- Section 6: High-Dimensional Descriptor Spaces -->
                <section id="high-dim">
                    <h2>6. Scaling to High-Dimensional Descriptor Spaces</h2>
                    <p>
                        Standard benchmarks use 2-4 dimensional descriptor spaces where grids are feasible.
                        But what happens when we push into territory where grids become impractical?
                    </p>

                    <h3>6.1. The Kheperax Maze Challenge</h3>
                    <p>
                        We tested DNS on Kheperax, a maze navigation task where agents must
                        traverse complex mazes. Unlike traditional maze tasks that only consider final position,
                        we characterize behavior using the agent's <em>entire trajectory</em> through the maze.
                    </p>
                    <p>
                        By sampling the agent's position at $n$ evenly-spaced intervals, we create descriptors
                        with $2n$ dimensions. With $n=30$ trajectory points, we get a 60-dimensional descriptor space.
                        This trajectory-based approach captures richer behavioral information, but creates
                        significant challenges for grid-based methods.
                    </p>

                    <h3>6.2. Why Grids Struggle</h3>

                    <ul>
                        <li><strong>Exponential cell growth:</strong> A grid with just 10 bins per dimension
                            would need $10^{60}$ cells for a 60D descriptor space.</li>
                        <li><strong>Infeasible combinations:</strong> Most trajectory combinations are physically
                            impossible (e.g., the robot teleporting across the maze between consecutive steps).</li>
                        <li><strong>Wasted resources:</strong> Grid cells allocated to unreachable regions
                            reduce the effective population size.</li>
                        <li><strong>Assume a fixed grid size:</strong> In truly open-ended environments, the descriptor space constantly changes as the population explores and develops.</li>
                    </ul>

                    <h3>6.3. Scaling with Dimensionality</h3>
                    <div class="opening-figure">
                        <div class="figure-title">Figure 4: Performance vs. Descriptor Dimensionality</div>
                        <div style="text-align: center; padding: 20px;">
                            <img src="images/kheperax_other_mean.png" alt="Kheperax Dimensionality Results" style="max-width: 100%; height: auto;">
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 4.</strong> QD-Score and Coverage as descriptor dimensionality increases
                            (from 2 to 100 trajectory points). DNS significantly outperforms all baselines for most
                            dimensionalities ($p < 0.05$), demonstrating robustness to the curse of dimensionality.
                        </div>
                    </div>

                    <p>
                        The results show that DNS maintains strong performance as dimensionality increases,
                        while MAP-Elites suffers from discretization inefficiencies. DNS can adapt its search
                        to the currently reachable portions of the descriptor space, leading to more effective
                        stepping-stone discovery even in high dimensions.
                    </p>

                    <h3>6.4. Unsupervised Descriptors</h3>
                    <p>
                        What if you don't know the descriptor space at all? In unsupervised QD (following the
                        AURORA algorithm), descriptors are learned as low-dimensional embeddings during evolution.
                        The space changes as the algorithm runs, making predefined bounds impossible.
                    </p>

                    <div class="opening-figure">
                        <div class="figure-title">Figure 5: Unsupervised Descriptor Space</div>
                        <div style="text-align: center; padding: 20px;">
                            <img src="images/kheperax_aurora_mean.png" alt="Kheperax AURORA Results" style="max-width: 100%; height: auto;">
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 5.</strong> Performance with learned (unsupervised) descriptors.
                            DNS significantly outperforms other methods in both QD-Score and Coverage ($p < 0.05$).
                            MAP-Elites cannot be applied since it requires predefined, fixed bounds.
                        </div>
                    </div>

                    <p>
                        This is where DNS truly shines: it adapts to learned descriptor spaces that are
                        unbounded and changing throughout evolution. MAP-Elites, which requires predefined
                        grids, simply cannot be applied in this scenario. Threshold-Elites requires complex
                        container size control mechanisms, while DNS achieves strong performance with its
                        simple competition mechanism.
                    </p>
                </section>

                <!-- Section 7: Discussion -->
                <section id="discussion">
                    <h2>7. What This Means for QD</h2>
                    <p>
                        The fundamental innovation of QD algorithms is not their collection mechanisms (grids, archives)
                        but rather <em>how they transform fitness based on local competition</em>. DNS makes this explicit
                        by replacing collection mechanisms entirely with a fitness transformation.
                    </p>
                    <p>
                        This has several implications:
                    </p>
                    <ul>
                        <li><strong>QD in high dimensions:</strong> DNS enables QD in descriptor spaces where grids are impossible.
                            This opens up applications using learned embeddings (CLIP, DINO, etc.) as diversity measures.</li>
                        <li><strong>Unsupervised QD:</strong> When descriptors come from a learned model (like an autoencoder or CLIP),
                            the descriptor space itself changes as the model updates. DNS handles this naturally: it doesn't need
                            fixed bounds or a predefined grid, so it can illuminate the descriptor space even as the underlying
                            representation shifts. This enables fully unsupervised QD where both the quality measure and the
                            diversity measure are learned.</li>
                        <li><strong>Enabling open-ended evolution:</strong> Open-ended systems require algorithms that work in unbounded, changing descriptor spaces. DNS meets these requirements: it needs no predefined bounds, adapts to learned embeddings that shift during evolution, and scales to high dimensions where grids are impossible. LeniaBreeder demonstrates this in practice, using DNS to generate unbounded diversity in artificial life.</li>
                        <li><strong>Simpler implementations:</strong> No grid management, no archive structures, no discretization
                            logic. Just a fitness transformation and standard evolutionary selection.</li>
                    </ul>

                    <h3>7.1. DNS in the Wild: LeniaBreeder</h3>
                    <p>
                        DNS has been used in <a href="https://leniabreeder.github.io/" target="_blank"><strong>LeniaBreeder</strong></a>,
                        a framework that automatically discovers diverse self-organizing patterns in Lenia, a continuous cellular automaton that produces lifelike artificial creatures.
                    </p>

                    <div class="opening-figure">
                        <div class="figure-title">Figure 6: LeniaBreeder - Discovering Artificial Life with DNS</div>
                        <div style="text-align: center; padding: 20px;">
                            <img src="images/LeniaBreeder.png" alt="LeniaBreeder diverse patterns" style="max-width: 60%; height: auto; border-radius: 4px;">
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 6.</strong> LeniaBreeder evolves in learned embedding spaces where grids are impossible,
                            generating diverse autonomous patterns exhibiting emergent complexity. The framework shows empirical
                            evidence of unbounded diversity, advancing toward truly open-ended evolution.
                        </div>
                    </div>

                    <p>
                        By evolving in learned embedding spaces, LeniaBreeder can discover patterns that weren't anticipated
                        in advance. This is exactly the kind of open-ended exploration that DNS enables: no predefined grid,
                        no fixed bounds, just evolution adapting to whatever structure emerges.
                    </p>

                    <h3>7.2. The Best of Both Worlds</h3>
                    <p>
                        Where does DNS sit in the landscape of evolutionary algorithms? Recent work by Faldor et al. [5] used
                        meta-learning to discover novel QD algorithms and mapped out the Pareto front between fitness and novelty.
                        DNS achieves the best of both worlds: near Novelty Search levels of diversity while maintaining
                        near GA/MAP-Elites levels of performance.
                    </p>

                    <div class="opening-figure">
                        <div class="figure-title">Figure 7: DNS on the Novelty-Fitness Pareto Front</div>
                        <div style="text-align: center; padding: 20px;">
                            <img src="images/plot_bbo_pareto_log.pdf" alt="Pareto front showing DNS achieving high novelty and high fitness" style="max-width: 70%; height: auto; border-radius: 4px;">
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 7.</strong> DNS (red star) achieves both high novelty (near Novelty Search) and high fitness
                            (near GA and MAP-Elites), placing it on the Pareto front of discovered QD algorithms. Figure from Faldor et al. [5].
                        </div>
                    </div>

                </section>

                <!-- Conclusion -->
                <section id="conclusion">
                    <h2>8. Conclusion</h2>
                    <p>
                        The MAP-Elites grid served QD well for over a decade. But as we push toward higher-dimensional
                        descriptor spaces and truly open-ended evolution, the grid becomes a limitation rather than a feature.
                    </p>
                    <p>
                        Dominated Novelty Search offers a path forward: the same local competition principles that make
                        QD powerful, without the artificial constraints of discretization. It's a drop-in replacement
                        that performs better, scales better, and adapts to whatever descriptor space your problem requires.
                    </p>
                    <p>
                        The grid is dead. Long live Dominated Novelty Search.
                    </p>

                    <div class="acknowledgments">
                        <strong>Acknowledgments.</strong> We thank Akarsh Kumar, Itamar Pres, and Navodita Sharma for comments on this blog post.
                        This work was supported in part by an NSF Graduate Research Fellowship to R.B.
                    </div>
                </section>

                <!-- References -->
                <section id="references">
                    <h2>References</h2>
                    <div style="text-align: left; font-size: 0.9em; line-height: 1.6;">
                        <p id="ref-1">[1] Bahlous-Boldi, R., Faldor, M., Grillotti, L., Janmohamed, H., Coiffard, L., Spector, L., & Cully, A. (2025). Dominated Novelty Search: Rethinking Local Competition in Quality-Diversity. <em>Proceedings of the Genetic and Evolutionary Computation Conference (GECCO)</em>. <a href="https://arxiv.org/abs/2502.00593" target="_blank">arXiv:2502.00593</a></p>

                        <p id="ref-2">[2] Mouret, J.-B., & Clune, J. (2015). Illuminating search spaces by mapping elites. <em>arXiv preprint arXiv:1504.04909</em>.</p>

                        <p id="ref-3">[3] Lehman, J., & Stanley, K. O. (2011). Abandoning objectives: Evolution through the search for novelty alone. <em>Evolutionary Computation</em>, 19(2), 189-223.</p>

                        <p id="ref-4">[4] Fontaine, M. C., & Nikolaidis, S. (2023). Differentiable Quality Diversity. <em>NeurIPS</em>.</p>

                        <p id="ref-5">[5] Faldor, M., Lange, R. T., & Cully, A. (2025). Discovering Quality-Diversity Algorithms via Meta-Black-Box Optimization. <em>arXiv preprint arXiv:2502.02190</em>.</p>
                    </div>
                </section>
            </article>
        </main>
    </div>
</body>
</html>
