<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dominated Novelty Search: Breaking Out of the Grid</title>
    <link rel="stylesheet" href="css/style.css">
    <!-- MathJax for LaTeX rendering -->
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script>
</head>
<body>
    <!-- Theme Toggle Button -->
    <button class="theme-toggle" id="theme-toggle" aria-label="Toggle dark mode">
        <span class="icon-sun">&#9728;</span>
        <span class="icon-moon">&#9790;</span>
    </button>

    <!-- Main Content -->
    <div class="main-wrapper">
        <!-- Header teaser banner -->
        <div class="header-banner">
            <img src="images/dns_header_banner.png" alt="DNS t-SNE embedding with sample portraits">
        </div>

        <header>
            <h1 class="title">The MAP-Elites Grid is Dead.<br>Long Live Dominated Novelty Search!</h1>

            <div class="author-list">
                <a href="https://ryanboldi.github.io" class="author-link highlighted">Ryan Bahlous-Boldi*<sup>1</sup></a>
                <span class="separator">·</span>
                <a href="https://maxencefaldor.github.io" class="author-link highlighted">Maxence Faldor*<sup>2</sup></a>
            </div>
            <div class="author-list secondary">
                <a href="https://lucagrillotti.github.io" class="author-link">Luca Grillotti<sup>2</sup></a>
                <span class="separator">·</span>
                <a href="#" class="author-link">Hannah Janmohamed<sup>2</sup></a>
                <span class="separator">·</span>
                <a href="#" class="author-link">Lisa Coiffard<sup>2</sup></a>
                <span class="separator">·</span>
                <a href="https://lspector.github.io" class="author-link">Lee Spector<sup>3</sup></a>
                <span class="separator">·</span>
                <a href="https://www.antoinecully.com" class="author-link">Antoine Cully<sup>2</sup></a>
            </div>
            <div class="affiliations">
                <span class="affiliation-item"><sup>1</sup>MIT CSAIL</span>
                <span class="affiliation-item"><sup>2</sup>Imperial College London</span>
                <span class="affiliation-item"><sup>3</sup>Amherst College</span>
            </div>

            <div class="paper-links">
                <a href="https://arxiv.org/abs/2502.00593" class="paper-btn" target="_blank">
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path><polyline points="14 2 14 8 20 8"></polyline><line x1="16" y1="13" x2="8" y2="13"></line><line x1="16" y1="17" x2="8" y2="17"></line><polyline points="10 9 9 9 8 9"></polyline></svg>
                    Paper
                </a>
                <a href="https://github.com/adaptive-intelligent-robotics/QDax" class="paper-btn" target="_blank">
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                    QDax
                </a>
                <a href="https://github.com/icaros-usc/pyribs" class="paper-btn" target="_blank">
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path></svg>
                    PyRibs
                </a>
            </div>

            <div class="paper-authors">
                GECCO 2025
            </div>
        </header>

        <style>
            .header-banner {
                max-width: 1600px;
                margin: 0 auto 20px;
                padding-top: 40px;
                text-align: center;
            }
            .header-banner img {
                max-width: 100%;
                height: auto;
                border-radius: 4px;
                box-shadow: 0 2px 8px rgba(0,0,0,0.1);
            }
        </style>

        <main>
            <!-- Abstract / Hook -->
            <div class="hook" id="hook">
                Quality-Diversity algorithms promise open-ended evolution, but they have been trapped in rigid grids.
                <strong>Dominated Novelty Search</strong> breaks free: a drop-in replacement for MAP-Elites that
                performs better, requires no discretization, and dynamically adapts to the descriptor space as
                evolution unfolds. It's QD without the grid, finally making Quality-Diversity truly open-ended.
            </div>

            <div class="hook-followup">
                <p>
                    For years, Quality-Diversity algorithms have relied on grids, archives, and predefined bounds
                    to manage populations. These mechanisms work, but they impose artificial constraints that limit
                    what QD can achieve. What if we could have all the benefits of local competition without any of
                    the discretization? What if QD could work in 512-dimensional embedding spaces where grids are
                    impossible?
                </p>
            </div>
        </main>

        <!-- Figure 1 - Full width outside main -->
        <div class="wide-figure" id="figure1">
            <div class="figure-title">Figure 1: Breaking Out of the Grid</div>
            <div style="text-align: center; padding: 20px;">
                <img src="images/DNS_diagram_v4.pdf" alt="DNS Diagram" style="max-width: 100%; height: auto;" onerror="this.style.display='none'; this.nextElementSibling.style.display='block';">
                <p style="color: #666; font-style: italic; display: none;">
                    The MAP-Elites grid is limited when the descriptor space: (a) has complex topology,
                    (b) is discontinuous, (c) is unbounded, or (d) is high-dimensional.
                </p>
            </div>
            <div class="figure-caption">
                <strong>Figure 1.</strong> The MAP-Elites grid struggles when the achievable descriptor space
                has complex topological shapes, is discontinuous, unbounded, or high-dimensional.
                Dominated Novelty Search adapts dynamically to the natural structure of the solution space.
            </div>
        </div>

        <main>
            <article>
                <!-- Introduction -->
                <section id="intro">
                    <p>
                        Quality-Diversity (QD) is a family of evolutionary algorithms that generate diverse, high-performing
                        solutions through local competition: the principle that solutions should only compete with similar
                        solutions, not the entire population. This insight, inspired by natural evolution, is what distinguishes
                        QD from traditional evolutionary algorithms.
                    </p>
                    <p>
                        But here's the thing: while research has focused on improving specific aspects of QD algorithms,
                        surprisingly little attention has been paid to the core mechanism itself. Most approaches implement
                        local competition through explicit collection mechanisms (fixed grids in MAP-Elites, or unstructured
                        archives in Novelty Search) that impose artificial constraints requiring predefined bounds or
                        hard-to-tune parameters.
                    </p>
                    <p>
                        <strong>Dominated Novelty Search</strong> takes a different approach. We show that QD methods can be
                        reformulated as Genetic Algorithms where local competition occurs through <em>fitness transformations</em>
                        rather than explicit collection mechanisms. DNS implements a novel competition strategy that dynamically
                        adapts to the shape and structure of the descriptor space, eliminating the need for predefined bounds,
                        grid structures, or fixed distance thresholds.
                    </p>
                    <p>
                        The result? A drop-in replacement for the grid mechanism in MAP-Elites that:
                    </p>
                    <ul>
                        <li>Significantly outperforms existing approaches across standard QD benchmarks</li>
                        <li>Works in high-dimensional descriptor spaces where grids are impossible</li>
                        <li>Requires no discretization, bounds, or threshold tuning</li>
                        <li>Is available in <a href="https://github.com/adaptive-intelligent-robotics/QDax">QDax</a> and <a href="https://github.com/icaros-usc/pyribs">PyRibs</a>, or can be implemented from scratch in ~10 lines of code</li>
                    </ul>
                </section>

                <!-- Section 2: The Problem with Grids -->
                <section id="problem">
                    <h2>2. The Problem with Grids</h2>
                    <p>
                        MAP-Elites, the most popular QD algorithm, works by dividing the descriptor space into a grid.
                        Each cell can hold exactly one solution: the best one found for that region. This is elegant and
                        simple, but it comes with fundamental limitations:
                    </p>
                    <ul>
                        <li><strong>The Dimensionality Problem:</strong> Grids scale exponentially with dimension. A 10×10 grid in 2D has 100 cells. Add a third dimension and you have 1,000 cells. With 10 dimensions, you need 10 billion cells. With the 512-dimensional CLIP embeddings we use in our experiments? You'd need $10^{512}$ cells, more than the number of atoms in the observable universe.</li>
                        <li><strong>The Bounds Problem:</strong> Traditional QD algorithms require you to specify bounds in advance: "poses range from -90° to +90°" or "lighting ranges from dark to bright." But what if you don't know the bounds? What if you're working with learned embeddings like CLIP where dimensions have no human-interpretable meaning?</li>
                        <li><strong>The Discretization Problem:</strong> Forcing continuous descriptor spaces into discrete cells throws away information. Two solutions at opposite corners of the same cell are treated as "the same location," even though they might be quite different. This limits the granularity of diversity that can be achieved.</li>
                    </ul>
                </section>

                <!-- Section 3: The Algorithm -->
                <section id="algorithm">
                    <h2>3. The Algorithm</h2>
                    <p>
                        Dominated Novelty Search implements local competition through a simple but powerful idea:
                        <em>a solution's survival depends on how different it is from solutions that are better than it</em>.
                    </p>
                    <p>
                        The key insight is that we can transform fitness values based on local competition, rather than
                        using explicit collection mechanisms. Here's how it works:
                    </p>

                    <h3>3.1. The Competition Function</h3>
                    <p>
                        For each solution $i$ in the population, we compute a "dominated novelty" score in three steps:
                    </p>

                    <div class="algorithm-box" id="algorithm-1">
                        <div class="algorithm-title">Algorithm 1: Dominated Novelty Search Competition</div>
                        <div class="algorithm-input">
                            <strong>Input:</strong> Population $\mathbf{X}$ with fitness values $\mathbf{f}$ and descriptors $\mathbf{d}$, locality parameter $k$
                        </div>
                        <div class="algorithm-output">
                            <strong>Output:</strong> Competition fitness $\tilde{f}_i$ for each solution $i$
                        </div>
                        <ol>
                            <li>
                                <span class="keyword">For</span> each solution $i$ in population:
                                <ol type="a">
                                    <li><strong>Identify dominating solutions:</strong> Find all solutions with superior fitness:
                                        $$\mathcal{D}_i = \{j \in \{1, \ldots, N\} \mid f_j > f_i\}$$
                                    </li>
                                    <li><strong>Compute descriptor distances:</strong> Calculate pairwise distances in descriptor space:
                                        $$d_{ij} = \|\mathbf{d}_i - \mathbf{d}_j\| \quad \forall j \in \mathcal{D}_i$$
                                    </li>
                                    <li><strong>Calculate dominated novelty score:</strong>
                                        $$\tilde{f}_i = \begin{cases}
                                            \frac{1}{k} \sum_{j \in \mathcal{K}_i} d_{ij} & \text{if } |\mathcal{D}_i| > 0 \\
                                            +\infty & \text{otherwise}
                                        \end{cases}$$
                                        where $\mathcal{K}_i$ contains indices of $k$ solutions in $\mathcal{D}_i$ with smallest distances.
                                    </li>
                                </ol>
                            </li>
                            <li><span class="keyword">Return</span> competition fitness $\tilde{\mathbf{f}}$</li>
                        </ol>
                    </div>

                    <p>
                        The intuition is elegant: <strong>a solution survives if it's either the best at what it does,
                        OR if it's doing something different from solutions that are better than it.</strong>
                    </p>
                    <ul>
                        <li><strong>Path 1: Be the best.</strong> If no one has higher fitness than you ($|\mathcal{D}_i| = 0$),
                            you automatically survive with infinite competition fitness.</li>
                        <li><strong>Path 2: Be different.</strong> If better solutions exist, you survive by being far away
                            from them in descriptor space. The farther you are from your $k$ nearest fitter neighbors,
                            the higher your competition fitness.</li>
                    </ul>

                    <h3>3.2. The Full Algorithm</h3>
                    <p>
                        The complete DNS algorithm follows the standard QD framework, with the competition function
                        replacing traditional grid or archive mechanisms:
                    </p>

                    <div class="algorithm-box" id="algorithm-2">
                        <div class="algorithm-title">Algorithm 2: Dominated Novelty Search</div>
                        <div class="algorithm-input">
                            <strong>Input:</strong> Population size $N$, batch size $B$, locality parameter $k$
                        </div>
                        <div class="algorithm-output">
                            <strong>Output:</strong> Final population $\mathbf{X}$
                        </div>
                        <ol>
                            <li><strong>Initialize:</strong> Population $\mathbf{X}$ with fitness $\mathbf{f}$ and descriptors $\mathbf{d}$</li>
                            <li><span class="keyword">While</span> not converged <span class="keyword">do</span>:
                                <ol type="a">
                                    <li><strong>Reproduce:</strong> Generate $B$ offspring using genetic operators</li>
                                    <li><strong>Concatenate:</strong> Add offspring to existing population</li>
                                    <li><strong>Evaluate:</strong> Compute fitness and descriptors for all solutions</li>
                                    <li><strong>Compete:</strong> Transform fitness via competition function (Algorithm 1)</li>
                                    <li><strong>Select:</strong> Retain top-$N$ individuals by competition fitness $\tilde{f}$</li>
                                </ol>
                            </li>
                            <li><span class="keyword">Return</span> population $\mathbf{X}$</li>
                        </ol>
                    </div>

                    <p>
                        The parameter $k$ controls the locality of competition. Small $k$ (like 3) means very local
                        competition: you only need to be different from your immediate neighborhood. Large $k$ means
                        broader competition: you need to be different from many better solutions.
                    </p>
                </section>

                <!-- Section 4: Code Comparison -->
                <section id="code">
                    <h2>4. Just 10 Lines of Code</h2>
                    <p>
                        Like MAP-Elites, DNS is remarkably simple to implement. Here's a side-by-side comparison showing
                        that DNS is just as elegant as the algorithms it replaces:
                    </p>

                    <!-- Code comparison figure -->
                    <div class="opening-figure">
                        <div class="figure-title">Code Comparison: MAP-Elites vs DNS</div>
                        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 50px; padding: 20px 60px; max-width: 1000px; margin: 0 auto;">
                            <div style="background: #1e1e1e; color: #d4d4d4; padding: 16px; border-radius: 4px; font-family: monospace; font-size: 10pt;">
                                <div style="color: #569cd6; margin-bottom: 8px;"># MAP-Elites</div>
                                <pre style="margin: 0; white-space: pre-wrap;">
def map_elites(pop, grid):
    for gen in range(N_GENS):
        # Select and mutate
        children = mutate(select(pop))
        # Evaluate
        fit, desc = evaluate(children)
        # Add to grid
        for i, (f, d) in enumerate(zip(fit, desc)):
            cell = discretize(d, grid)
            if f > grid[cell].fitness:
                grid[cell] = children[i]
    return grid</pre>
                            </div>
                            <div style="background: #1e1e1e; color: #d4d4d4; padding: 16px; border-radius: 4px; font-family: monospace; font-size: 10pt;">
                                <div style="color: #569cd6; margin-bottom: 8px;"># Dominated Novelty Search</div>
                                <pre style="margin: 0; white-space: pre-wrap;">
def dns(pop, k=3):
    for gen in range(N_GENS):
        # Select and mutate
        children = mutate(select(pop))
        # Evaluate
        fit, desc = evaluate(children)
        # Merge and compete
        pop = concat(pop, children)
        scores = dominated_novelty(pop, k)
        # Keep top N
        pop = top_n(pop, scores, N)
    return pop</pre>
                            </div>
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 2.</strong> MAP-Elites requires discretizing the descriptor space into a grid.
                            DNS replaces this with a continuous competition function: no grid, no bounds, no discretization.
                        </div>
                    </div>

                    <p>
                        The key difference: MAP-Elites uses <code>discretize()</code> and a grid structure. DNS uses
                        <code>dominated_novelty()</code>, a function that computes competition scores based on distances
                        to fitter neighbors. Everything else is the same standard evolutionary loop.
                    </p>
                </section>

                <!-- Section 5: Benchmark Results -->
                <section id="benchmarks">
                    <h2>5. Benchmark Results</h2>
                    <p>
                        We evaluated DNS against MAP-Elites, Threshold-Elites, and Cluster-Elites across standard
                        continuous control benchmarks: Walker (bipedal locomotion), Ant (quadrupedal movement),
                        and Ant Blocks (navigation with obstacles). Each experiment was repeated 10 times with
                        different seeds, using Mann-Whitney U tests with Holm-Bonferroni correction for statistical significance.
                    </p>

                    <div class="opening-figure">
                        <div class="figure-title">Figure 3: Benchmark Performance</div>
                        <div style="text-align: center; padding: 20px;">
                            <img src="images/all_environments_metrics_plot_4.png" alt="Benchmark Results" style="max-width: 100%; height: auto;">
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 3.</strong> QD-Score and Coverage over generations across MuJoCo environments.
                            DNS significantly outperforms Threshold-Elites and Cluster-Elites across all environments ($p < 10^{-9}$),
                            and outperforms MAP-Elites in Walker and Ant Blocks ($p < 10^{-3}$) where implicit constraints
                            limit the reachable descriptor space.
                        </div>
                    </div>

                    <p>
                        Key findings from the benchmarks:
                    </p>
                    <ul>
                        <li><strong>Walker:</strong> DNS significantly outperforms MAP-Elites because certain foot-contact
                            proportions (like both feet never touching ground) are infeasible, leaving grid cells empty.</li>
                        <li><strong>Ant Blocks:</strong> Obstacles create discontinuous descriptor spaces where some regions
                            are unreachable, wasting MAP-Elites grid cells.</li>
                        <li><strong>Ant:</strong> DNS and MAP-Elites perform competitively when the descriptor space
                            (final x,y position) aligns well with a 2D grid.</li>
                    </ul>
                </section>

                <!-- Section 6: High-Dimensional Descriptor Spaces -->
                <section id="high-dim">
                    <h2>6. Scaling to High-Dimensional Descriptor Spaces</h2>
                    <p>
                        Standard benchmarks use 2-4 dimensional descriptor spaces where grids are feasible.
                        But what happens when we push into territory where grids become impractical?
                    </p>

                    <h3>6.1. The Kheperax Maze Challenge</h3>
                    <p>
                        We tested DNS on the Kheperax environment: a maze navigation task where agents must
                        traverse complex mazes. Unlike traditional maze tasks that only consider final position,
                        we characterize behavior using the agent's <em>entire trajectory</em> through the maze.
                    </p>
                    <p>
                        By sampling the agent's position at $n$ evenly-spaced intervals, we create descriptors
                        with $2n$ dimensions. With $n=30$ trajectory points, we get a 60-dimensional descriptor space.
                        This trajectory-based approach captures richer behavioral information, but creates
                        significant challenges for grid-based methods.
                    </p>

                    <h3>6.2. Why Grids Struggle</h3>
                    <p>
                        As dimensionality increases, the curse of dimensionality hits hard:
                    </p>
                    <ul>
                        <li><strong>Exponential cell growth:</strong> A grid with just 10 bins per dimension
                            would need $10^{60}$ cells for a 60D descriptor space.</li>
                        <li><strong>Infeasible combinations:</strong> Most trajectory combinations are physically
                            impossible (e.g., the robot teleporting across the maze between consecutive steps).</li>
                        <li><strong>Wasted resources:</strong> Grid cells allocated to unreachable regions
                            reduce the effective population size.</li>
                    </ul>

                    <h3>6.3. Results: Scaling with Dimensionality</h3>
                    <div class="opening-figure">
                        <div class="figure-title">Figure 4: Performance vs. Descriptor Dimensionality</div>
                        <div style="text-align: center; padding: 20px;">
                            <img src="images/kheperax_other_mean.png" alt="Kheperax Dimensionality Results" style="max-width: 100%; height: auto;">
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 4.</strong> QD-Score and Coverage as descriptor dimensionality increases
                            (from 2 to 100 trajectory points). DNS significantly outperforms all baselines for most
                            dimensionalities ($p < 0.05$), demonstrating robustness to the curse of dimensionality.
                        </div>
                    </div>

                    <p>
                        The results show that DNS maintains strong performance as dimensionality increases,
                        while MAP-Elites suffers from discretization inefficiencies. DNS can adapt its search
                        to the currently reachable portions of the descriptor space, leading to more effective
                        stepping-stone discovery even in high dimensions.
                    </p>

                    <h3>6.4. Unsupervised Descriptors</h3>
                    <p>
                        What if you don't know the descriptor space at all? In unsupervised QD (following the
                        AURORA algorithm), descriptors are learned as low-dimensional embeddings during evolution.
                        The space changes as the algorithm runs, making predefined bounds impossible.
                    </p>

                    <div class="opening-figure">
                        <div class="figure-title">Figure 5: Unsupervised Descriptor Space</div>
                        <div style="text-align: center; padding: 20px;">
                            <img src="images/kheperax_aurora_mean.png" alt="Kheperax AURORA Results" style="max-width: 100%; height: auto;">
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 5.</strong> Performance with learned (unsupervised) descriptors.
                            DNS significantly outperforms other methods in both QD-Score and Coverage ($p < 0.05$).
                            MAP-Elites cannot be applied since it requires predefined, fixed bounds.
                        </div>
                    </div>

                    <p>
                        This is where DNS truly shines: it adapts to learned descriptor spaces that are
                        unbounded and changing throughout evolution. MAP-Elites, which requires predefined
                        grids, simply cannot be applied in this scenario. Threshold-Elites requires complex
                        container size control mechanisms, while DNS achieves strong performance with its
                        simple competition mechanism.
                    </p>
                </section>

                <!-- Section 7: Application - Diverse Image Generation -->
                <section id="diffusion">
                    <h2>7. Application: Diverse Portrait Generation with Stable Diffusion</h2>
                    <p>
                        The Kheperax experiments show DNS works in high dimensions, but let's push further.
                        What about 512-dimensional CLIP embeddings? This is where DNS enables applications
                        that were previously impossible with grid-based QD.
                    </p>

                    <h3>7.1. The Challenge: Diverse Portraits of Tom Cruise</h3>
                    <p>
                        When you ask Stable Diffusion to generate "a portrait of Tom Cruise," you get the same image
                        over and over. Minor pixel variations exist, but the pose, lighting, expression, and style all
                        converge toward a single "average" Tom Cruise. This is mode collapse: the AI gets stuck producing
                        the most statistically likely output.
                    </p>
                    <p>
                        What if we could teach the AI to automatically explore all the different ways a person could look,
                        while ensuring every image actually looks like that person?
                    </p>

                    <h3>7.2. The CLIP-Based Approach</h3>
                    <p>
                        The key insight is that text prompts are a crude steering wheel. The real magic happens in
                        <em>latent space</em>, the high-dimensional mathematical space where Stable Diffusion "thinks."
                        Different latent vectors produce different images, even with the same prompt. Most are garbage,
                        but somewhere in that vast 16,384-dimensional latent space exist vectors that produce stunning,
                        diverse, high-quality portraits.
                    </p>
                    <p>
                        We treat image generation as an evolutionary optimization problem. Instead of evolving living
                        creatures, we evolve latent vectors. For each generated image, CLIP provides both our fitness
                        and diversity measures:
                    </p>

                    <table class="data-table" style="max-width: 600px; margin: 20px auto;">
                        <thead>
                            <tr>
                                <th>Role</th>
                                <th>What It Measures</th>
                                <th>Source</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><strong>Fitness</strong></td>
                                <td>"Is this Tom Cruise?"</td>
                                <td>CLIP text-image cosine similarity</td>
                            </tr>
                            <tr>
                                <td><strong>Descriptor</strong></td>
                                <td>"What variant is it?"</td>
                                <td>CLIP image embedding (pose, lighting, style)</td>
                            </tr>
                        </tbody>
                    </table>

                    <p>
                        We first encode the target text "Tom Cruise" with CLIP's text encoder, giving us a 512-dimensional
                        reference vector. For each generated image, we compute its CLIP image embedding. The fitness is
                        simply the cosine similarity between the image embedding and the text embedding—higher similarity
                        means the image better matches "Tom Cruise." The descriptor is the image embedding itself, capturing
                        all the visual attributes like pose, lighting, and style in 512 dimensions.
                    </p>
                    <p>
                        DNS then selects for individuals that are both high-fitness AND diverse: you survive if you're
                        novel compared to solutions that beat you on fitness. This elegantly balances identity preservation
                        with visual diversity.
                    </p>

                    <h3>7.3. Why This Couldn't Be Done Before</h3>
                    <p>
                        <strong>The Grid Problem:</strong> CLIP embeddings have 512 dimensions. Even with just 2 bins
                        per dimension, you'd need $2^{512}$ cells, more than atoms in the observable universe.
                    </p>
                    <p>
                        <strong>The Bounds Problem:</strong> We don't know what CLIP dimensions mean. Dimension 237 might
                        encode "glasses-ness" combined with "outdoor lighting" combined with "smile intensity." There's
                        no human-interpretable structure to bound.
                    </p>
                    <p>
                        <strong>DNS solves both:</strong> It doesn't discretize space; it works in continuous
                        high-dimensional embeddings. It doesn't need bounds; it adapts to whatever region of space
                        the population naturally explores.
                    </p>

                    <h3>7.4. Results</h3>

                    <!-- Interactive CLIP space visualization -->
                    <div class="opening-figure" id="clip-viz-figure">
                        <div class="figure-title">Figure 7: Population in CLIP Embedding Space (Interactive)</div>
                        <div class="clip-viz-container">
                            <div class="clip-viz-main">
                                <canvas id="clip-canvas"></canvas>
                                <div class="clip-hover-preview" id="clip-hover-preview">
                                    <img id="clip-hover-img" src="" alt="">
                                    <div class="clip-hover-info">
                                        <span class="clip-hover-fitness" id="clip-hover-fitness"></span>
                                    </div>
                                </div>
                            </div>
                            <div class="clip-viz-legend">
                                <div class="clip-legend-title">Identity Match (Fitness)</div>
                                <div class="clip-color-bar"></div>
                                <div class="clip-legend-labels">
                                    <span>Low</span>
                                    <span>High</span>
                                </div>
                                <div class="clip-stats">
                                    <p><strong>5,000</strong> evolved portraits</p>
                                    <p><strong>512-dim</strong> CLIP embeddings</p>
                                    <p>Projected via <strong>t-SNE</strong></p>
                                </div>
                                <p class="clip-instruction">Hover over points to see portraits</p>
                            </div>
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 7.</strong> Projection of the evolved population in CLIP embedding space.
                            DNS spreads solutions across the reachable regions while maintaining high fitness (identity match).
                            No grid was needed; the algorithm naturally discovered the structure of the space.
                            <em>Points colored by identity match score (yellow = higher match).</em>
                        </div>
                    </div>

                    <style>
                        .clip-viz-container {
                            display: flex;
                            gap: 20px;
                            padding: 20px;
                            background: var(--bg-paper);
                            justify-content: center;
                            align-items: flex-start;
                        }
                        .clip-viz-main {
                            position: relative;
                            width: 700px;
                            height: 700px;
                            border: 1px solid var(--border-color);
                            background: var(--bg-subtle);
                        }
                        #clip-canvas {
                            width: 100%;
                            height: 100%;
                            cursor: crosshair;
                        }
                        .clip-hover-preview {
                            position: absolute;
                            display: none;
                            pointer-events: none;
                            z-index: 100;
                            background: var(--bg-paper);
                            border: 2px solid var(--border-color);
                            border-radius: 4px;
                            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
                            overflow: hidden;
                        }
                        .clip-hover-preview.visible {
                            display: block;
                        }
                        #clip-hover-img {
                            width: 150px;
                            height: 150px;
                            object-fit: cover;
                            display: block;
                        }
                        .clip-hover-info {
                            padding: 6px 8px;
                            font-size: 9pt;
                            text-align: center;
                            background: var(--bg-subtle);
                            border-top: 1px solid var(--border-light);
                        }
                        .clip-hover-fitness {
                            font-family: var(--font-mono);
                            color: var(--text-secondary);
                        }
                        .clip-viz-legend {
                            width: 140px;
                            padding: 15px;
                            background: var(--bg-subtle);
                            border: 1px solid var(--border-light);
                            border-radius: 4px;
                        }
                        .clip-legend-title {
                            font-size: 9pt;
                            font-weight: 700;
                            margin-bottom: 8px;
                            color: var(--text-primary);
                        }
                        .clip-color-bar {
                            height: 12px;
                            border-radius: 2px;
                            background: linear-gradient(to right, #440154, #482878, #3e4a89, #31688e, #26828e, #1f9e89, #35b779, #6ece58, #b5de2b, #fde725);
                            margin-bottom: 4px;
                        }
                        .clip-legend-labels {
                            display: flex;
                            justify-content: space-between;
                            font-size: 8pt;
                            color: var(--text-secondary);
                            margin-bottom: 15px;
                        }
                        .clip-stats {
                            font-size: 9pt;
                            color: var(--text-secondary);
                            line-height: 1.6;
                        }
                        .clip-stats p {
                            margin: 4px 0;
                            text-align: left;
                        }
                        .clip-stats strong {
                            color: var(--text-primary);
                        }
                        .clip-instruction {
                            font-size: 8pt;
                            color: var(--text-secondary);
                            font-style: italic;
                            margin-top: 15px;
                            text-align: center;
                        }
                        @media (max-width: 900px) {
                            .clip-viz-container {
                                flex-direction: column;
                                align-items: center;
                            }
                            .clip-viz-main {
                                width: 100%;
                                max-width: 500px;
                                height: 500px;
                            }
                            .clip-viz-legend {
                                width: 100%;
                                max-width: 500px;
                            }
                        }
                    </style>

                    <script>
                    (function() {
                        let clipData = null;
                        let clipCanvas, clipCtx;
                        let clipHoveredIdx = -1;
                        const POINT_SIZE = 3;
                        const PADDING = 20;

                        // Viridis color scale
                        function viridisColor(t) {
                            t = Math.max(0, Math.min(1, t));
                            const colors = [
                                [68, 1, 84], [72, 40, 120], [62, 74, 137], [49, 104, 142],
                                [38, 130, 142], [31, 158, 137], [53, 183, 121], [110, 206, 88],
                                [181, 222, 43], [253, 231, 37]
                            ];
                            const idx = t * (colors.length - 1);
                            const i = Math.floor(idx);
                            const f = idx - i;
                            if (i >= colors.length - 1) return `rgb(${colors[colors.length-1].join(',')})`;
                            const c1 = colors[i], c2 = colors[i + 1];
                            return `rgb(${Math.round(c1[0] + f * (c2[0] - c1[0]))},${Math.round(c1[1] + f * (c2[1] - c1[1]))},${Math.round(c1[2] + f * (c2[2] - c1[2]))})`;
                        }

                        function drawClipViz() {
                            if (!clipData || !clipCanvas) return;
                            const container = document.querySelector('.clip-viz-main');
                            const width = container.offsetWidth;
                            const height = container.offsetHeight;
                            const isDark = document.documentElement.getAttribute('data-theme') === 'dark';

                            clipCtx.fillStyle = isDark ? '#242424' : '#fafafa';
                            clipCtx.fillRect(0, 0, width, height);

                            const minFit = Math.min(...clipData.fitness);
                            const maxFit = Math.max(...clipData.fitness);

                            // Draw points
                            for (let i = 0; i < clipData.n; i++) {
                                const [nx, ny] = clipData.coords[i];
                                const x = PADDING + nx * (width - 2 * PADDING);
                                const y = PADDING + ny * (height - 2 * PADDING);
                                const fitNorm = (clipData.fitness[i] - minFit) / (maxFit - minFit);

                                clipCtx.beginPath();
                                clipCtx.arc(x, y, i === clipHoveredIdx ? POINT_SIZE + 2 : POINT_SIZE, 0, Math.PI * 2);
                                clipCtx.fillStyle = viridisColor(fitNorm);
                                clipCtx.fill();

                                if (i === clipHoveredIdx) {
                                    clipCtx.strokeStyle = isDark ? '#fff' : '#000';
                                    clipCtx.lineWidth = 2;
                                    clipCtx.stroke();
                                }
                            }
                        }

                        function getClipPointAt(mx, my) {
                            if (!clipData) return -1;
                            const container = document.querySelector('.clip-viz-main');
                            const width = container.offsetWidth;
                            const height = container.offsetHeight;
                            let closest = -1, minDist = 15;

                            for (let i = 0; i < clipData.n; i++) {
                                const [nx, ny] = clipData.coords[i];
                                const x = PADDING + nx * (width - 2 * PADDING);
                                const y = PADDING + ny * (height - 2 * PADDING);
                                const dist = Math.sqrt((mx - x) ** 2 + (my - y) ** 2);
                                if (dist < minDist) {
                                    minDist = dist;
                                    closest = i;
                                }
                            }
                            return closest;
                        }

                        function showClipPreview(idx, clientX, clientY) {
                            const preview = document.getElementById('clip-hover-preview');
                            const img = document.getElementById('clip-hover-img');
                            const fitness = document.getElementById('clip-hover-fitness');

                            if (idx < 0) {
                                preview.classList.remove('visible');
                                return;
                            }

                            img.src = `dns_clip_web_viewer/images/${idx}.jpg`;
                            fitness.textContent = `Identity: ${(clipData.fitness[idx] * 100).toFixed(1)}%`;
                            preview.classList.add('visible');

                            // Position preview near cursor but within bounds
                            const container = document.querySelector('.clip-viz-main');
                            const rect = container.getBoundingClientRect();
                            let left = clientX - rect.left + 15;
                            let top = clientY - rect.top - 75;

                            // Keep within container bounds
                            if (left + 160 > container.offsetWidth) left = clientX - rect.left - 170;
                            if (top < 0) top = clientY - rect.top + 15;
                            if (top + 180 > container.offsetHeight) top = container.offsetHeight - 185;

                            preview.style.left = left + 'px';
                            preview.style.top = top + 'px';
                        }

                        function initClipViz() {
                            clipCanvas = document.getElementById('clip-canvas');
                            if (!clipCanvas) return;

                            clipCtx = clipCanvas.getContext('2d');

                            // Set canvas resolution
                            const container = document.querySelector('.clip-viz-main');
                            const dpr = window.devicePixelRatio || 1;
                            clipCanvas.width = container.offsetWidth * dpr;
                            clipCanvas.height = container.offsetHeight * dpr;
                            clipCtx.scale(dpr, dpr);

                            // Load data
                            fetch('dns_clip_web_viewer/metadata.json')
                                .then(r => r.json())
                                .then(data => {
                                    clipData = data;
                                    drawClipViz();
                                })
                                .catch(err => console.error('Failed to load CLIP data:', err));

                            // Mouse events for hover preview
                            clipCanvas.addEventListener('mousemove', (e) => {
                                const rect = clipCanvas.getBoundingClientRect();
                                const mx = e.clientX - rect.left;
                                const my = e.clientY - rect.top;

                                const idx = getClipPointAt(mx, my);
                                if (idx !== clipHoveredIdx) {
                                    clipHoveredIdx = idx;
                                    drawClipViz();
                                }
                                showClipPreview(idx, e.clientX, e.clientY);
                            });

                            clipCanvas.addEventListener('mouseleave', () => {
                                clipHoveredIdx = -1;
                                drawClipViz();
                                showClipPreview(-1, 0, 0);
                            });

                            // Redraw on theme change
                            const observer = new MutationObserver(() => drawClipViz());
                            observer.observe(document.documentElement, { attributes: true, attributeFilter: ['data-theme'] });

                            // Redraw on resize
                            window.addEventListener('resize', () => {
                                const dpr = window.devicePixelRatio || 1;
                                clipCanvas.width = container.offsetWidth * dpr;
                                clipCanvas.height = container.offsetHeight * dpr;
                                clipCtx.scale(dpr, dpr);
                                drawClipViz();
                            });
                        }

                        // Initialize when DOM is ready
                        if (document.readyState === 'loading') {
                            document.addEventListener('DOMContentLoaded', initClipViz);
                        } else {
                            initClipViz();
                        }
                    })();
                    </script>

                    <div class="opening-figure">
                        <div class="figure-title">Figure 8: Principal Components of Variation</div>
                        <div style="text-align: center; padding: 20px;">
                            <img src="images/dns_pca_variations.png" alt="PCA variation grid of Tom Cruise portraits" style="max-width: 100%; height: auto; border-radius: 4px;">
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 8.</strong> Portraits sampled along the two principal components of variation
                            in the embedding space. Moving left-to-right (PC1) and bottom-to-top (PC2) reveals systematic
                            changes in pose, lighting, and style. DNS discovers these meaningful axes of variation without
                            any explicit supervision—the structure emerges purely from the diversity pressure.
                        </div>
                    </div>

                    <p>
                        This is exactly what QD promises: not finding the single best answer, but illuminating the
                        full landscape of good answers. And because DNS requires no grids, bounds, or thresholds,
                        it scales gracefully to the high-dimensional embedding spaces that modern AI systems use.
                    </p>
                </section>

                <!-- Section 8: Discussion -->
                <section id="discussion">
                    <h2>8. Discussion: What This Means for QD</h2>
                    <p>
                        The fundamental innovation of QD algorithms is not their collection mechanisms (grids, archives)
                        but rather <em>how they transform fitness based on local competition</em>. DNS makes this explicit
                        by replacing collection mechanisms entirely with a fitness transformation.
                    </p>
                    <p>
                        This has several implications:
                    </p>
                    <ul>
                        <li><strong>QD in high dimensions:</strong> DNS enables QD in descriptor spaces where grids are impossible.
                            This opens up applications using learned embeddings (CLIP, DINO, etc.) as diversity measures.</li>
                        <li><strong>Truly open-ended evolution:</strong> Without predefined bounds, DNS can discover regions of
                            descriptor space that weren't anticipated. The algorithm adapts as evolution unfolds.</li>
                        <li><strong>Simpler implementations:</strong> No grid management, no archive structures, no discretization
                            logic. Just a fitness transformation and standard evolutionary selection.</li>
                    </ul>

                    <!-- TODO: Manim animation placeholder -->
                    <div class="opening-figure">
                        <div class="figure-title">Figure 9: How DNS Works (Animation)</div>
                        <div style="text-align: center; padding: 60px; background: #eee; border: 2px dashed #999;">
                            <p style="color: #666; font-style: italic;">
                                [PLACEHOLDER: Manim animation]<br><br>
                                Animated visualization showing:<br>
                                1. Population in descriptor space<br>
                                2. For each solution, highlight its dominating neighbors<br>
                                3. Show how competition scores are computed<br>
                                4. Visualize selection process<br><br>
                                Could be an embedded video or interactive widget
                            </p>
                        </div>
                        <div class="figure-caption">
                            <strong>Figure 9.</strong> Animation showing how DNS computes competition scores and selects
                            solutions. Each solution competes only with fitter solutions in its local neighborhood,
                            creating natural niches without explicit grid structures.
                        </div>
                    </div>
                </section>

                <!-- Section 9: Getting Started -->
                <section id="getting-started">
                    <h2>9. Getting Started</h2>
                    <p>
                        DNS is available in two popular QD libraries:
                    </p>
                    <ul>
                        <li><strong><a href="https://github.com/adaptive-intelligent-robotics/QDax">QDax</a></strong> (JAX-based, GPU-accelerated)</li>
                        <li><strong><a href="https://github.com/icaros-usc/pyribs">PyRibs</a></strong> (Python, NumPy-based)</li>
                    </ul>
                    <p>
                        Switching from MAP-Elites to DNS is typically a one-line change: replace the archive/grid
                        mechanism with DNS competition, and you're ready to go.
                    </p>
                    <p>
                        Alternatively, DNS is simple enough to implement from scratch. The core algorithm is just
                        ~10 lines of code (see Section 4), making it easy to integrate into any existing evolutionary
                        framework without external dependencies.
                    </p>

                    <!-- TODO: Code snippet for getting started -->
                    <div style="background: #1e1e1e; color: #d4d4d4; padding: 16px; border-radius: 4px; font-family: monospace; font-size: 10pt; margin: 20px 0;">
                        <div style="color: #569cd6; margin-bottom: 8px;"># Example: Using DNS in QDax</div>
                        <pre style="margin: 0; white-space: pre-wrap; color: #6a9955;">
# TODO: Add actual code example from QDax/PyRibs</pre>
                    </div>
                </section>

                <!-- Conclusion -->
                <section id="conclusion">
                    <h2>10. Conclusion</h2>
                    <p>
                        The MAP-Elites grid served QD well for over a decade. But as we push toward higher-dimensional
                        descriptor spaces and truly open-ended evolution, the grid becomes a limitation rather than a feature.
                    </p>
                    <p>
                        Dominated Novelty Search offers a path forward: the same local competition principles that make
                        QD powerful, without the artificial constraints of discretization. It's a drop-in replacement
                        that performs better, scales better, and adapts to whatever descriptor space your problem requires.
                    </p>
                    <p>
                        The grid is dead. Long live Dominated Novelty Search.
                    </p>

                    <div class="acknowledgments">
                        <strong>Acknowledgments.</strong> We thank Luca Grillotti, Hannah Janmohamed, Lisa Coiffard,
                        Lee Spector, and Antoine Cully for their contributions to the original paper. We also thank
                        Akarsh Kumar for comments on this blog post.
                    </div>
                </section>

                <!-- References -->
                <section id="references">
                    <h2>References</h2>
                    <div style="text-align: left; font-size: 0.9em; line-height: 1.6;">
                        <p id="ref-1">[1] Bahlous-Boldi, R., Faldor, M., Grillotti, L., Janmohamed, H., Coiffard, L., Spector, L., & Cully, A. (2025). Dominated Novelty Search: Rethinking Local Competition in Quality-Diversity. <em>Proceedings of the Genetic and Evolutionary Computation Conference (GECCO)</em>. <a href="https://arxiv.org/abs/2502.00593" target="_blank">arXiv:2502.00593</a></p>

                        <p id="ref-2">[2] Mouret, J.-B., & Clune, J. (2015). Illuminating search spaces by mapping elites. <em>arXiv preprint arXiv:1504.04909</em>.</p>

                        <p id="ref-3">[3] Lehman, J., & Stanley, K. O. (2011). Abandoning objectives: Evolution through the search for novelty alone. <em>Evolutionary Computation</em>, 19(2), 189-223.</p>

                        <p id="ref-4">[4] Fontaine, M. C., & Nikolaidis, S. (2023). Differentiable Quality Diversity. <em>NeurIPS</em>.</p>
                    </div>
                </section>
            </article>
        </main>
    </div>

    <script src="js/theme.js"></script>
</body>
</html>
